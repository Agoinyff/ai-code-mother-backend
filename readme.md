
## 目前已经能够实现调用AI生成代码，但是直接返回字符串的方式不便于后续解析代码并保存为文件。因此需要一种更结构化的方式来返回代码片段
     
我们可以利用LangChain4j的结构化输出特性解决这一点
### 1. 构建生成结果类
### 2.修改AI服务接口，让方法返回结构化对象


之后我们需要把AI生成的代码保存到本地中，这就需要一个文件写入的工具类
  -- 这里使用门面模式设计模式，简化文件写入的操作

## 上一步完成之后，就可以实现一个完整的AI代码生成并保存到本地的功能，但是发现了一个问题，就是结构化输出的速度比较慢，用户需要等待较长的时间才能看到结果，这种体验显然不够好
### 1.为了提升用户体验，引入SSE流式输出，但是目前的流式输出方案并不支持结构化输出，所以选择在流式返回的过程中拼接AI的返回结果，等全部输出完成后，再对拼接结果进行解析和保存，这样既保证了实时性，又不影响最终的处理流程

### 2.选择使用LangChain4j + Reactor实现流式结构化输出

## 完成了流式构造StringBuilder的功能,正则解析得到模板并存在本地，这时候会发现写了好多的重复代码，可以通过几种设计模式来优化代码结构
解析器部分：使用策略模式，不同类型的解析策略独立维护
文件保存部分:使用模板方法模式，统一保存流程
SSE流式处理：抽象出通用的流式处理逻辑

### 使用执行器模式和策略模式和模板方法模式混用
这是一个非常经典的**“三剑客”组合**。在复杂的企业级开发（尤其是 Java 后端）中，这种组合能极大地解决代码臃肿、逻辑耦合和难以扩展的问题。


## 使用AI生成App的基础的增删查改方法
### 1. 现在需要将之前实现的AI生成功能与应用管理系统进行集成
### 2. 参考大厂平台，我们的整个业务流程是：
用户在主页输入提示词创建应用(入库)
获取应用ID后转跳到对话页面
系统自动使用初始提示词与AI对话生成代码

## 在完成流式接口之后，遇到一个问题就是，前端无法解析流式返回的碎片化数据，前端无法知道什么时候结束
### 1. 解决方案是后端在流式返回的过程中，对每一次结果都进行一次封装，封装到json中,将Flux额外封装成ServerSentEvent
### 2. 前端接收到每一次流式数据后，进行json解析，判断是否是结束标志，如果是结束标志则停止接收
为什么要封装成 ServerSentEvent？
直接返回 Flux 就像是在发短信只发内容；而封装成 ServerSentEvent 就像是在发带格式的信件，它允许你自定义：

id：给每条消息一个唯一 ID，客户端断开重连时可以告诉服务器“我收到哪一条了”。

event：自定义事件名称。前端可以用 addEventListener('eventName', ...) 监听特定的事件，而不仅仅是 onmessage。

retry：告诉客户端如果连接断了，隔多少毫秒再重试。

comment：发送注释（通常用于心跳包，防止连接超时）。

## 下一个需求就是实现后端的应用部署功能，之前是在本地手动双击打开HTML文件来查看网站生成效果的，但是用户使用的时候肯定不是这样，所以我们需要把AI生成的网站同步到web服务器上，让用户可以通过浏览器访问，即使的看到效果，可以选择同服务器的不同目录，也可以选择不同服务器，显然前者成本更低，但是用户量大的话，就需要进行分离。有以下几种方式进行部署
### 1.使用Serve工具：通过Node.js的Serve工具，可以快速启动一个web服务器，为指定目录提供Web访问服务。使用时，只需要提前在服务器上启动serve服务器，就能为特定部署目录提供web服务。这种方案的优点是配置简单，缺点是依赖Node.js环境，需要独立启动Web服务进程，而且性能相对较低。虽然我们可以直接让serve服务器跟随springboot项目启动，使用Java启动外部进程的工具类，但是还是不推荐，因为性能不行
### 2.使用springboot接口：可以直接在后端项目中实现一个静态资源服务器接口，输入部署路径，返回相应的文件。这种方案的优点是无需额外进程，但是功能相对简单，性能也不如专业的Web服务器
### 3.使用Nginx映射：这是在生产环境中推荐的方案，性能最佳，唯一的缺点就是要额外引入Nginx组件
### 4.使用对象存储服务：提供访问和存储功能，用户量大可选这个功能（推荐）
## 基于以上分析，选择混合方案，使用springboot接口实现AI生成的网页预览，使用Nginx提供网站的部署服务
### 校验参数，生成deployKey（为了简化访问地址，直接将deployKey作为文件名），部署操作(本质就是将原本在code_output目录下的文件复制到code_deploy目录下)

## 上述步骤之后出现了一些问题需要解决，每次对话都是独立的，AI无法记住之前的交互内容，这导致用户无法基于已经生成的网站进行迭代修改，因此有以下需求
### 1.对话历史的持久化存储：用户发送消息的时候需要保存用户的消息，AI成功回复之后，即使AI回复失败，也要记录错误信息，确保对话的完整性。
### 2.应用级别的数据隔离：每个应用的对话历史都是独立的，删除应用时，需要把关联此应用的对话记录全部删除
### 3.对话历史查询：支持分页查看某个应用的对话历史，需要区分用户和AI消息。类似聊天软件的加载机制，每次加载最新的10条消息，支持向前加载更多历史记录。（仅应用创建者和管理员可见）
### 4.管理对话历史：管理员可以查看所有应用的对话历史，按照时间降序，便于内容监管

## 但是这里出现了一个问题，对于对话历史的查询不能使用传统的分页查询，传统的分页查询是基于页码或偏移量进行的，如果数据在分页的过程中发生了变化，会导致用户看到的分页数据出现不一致。而且传统的分页方式在处理大量的对话数据时会出现严重的性能问题，假设一个热门应用积累了几万条的对话记录后，如果用户想查看早期的历史消息，执行分页查询会很慢 
### 为了解决这个问题，可以使用游标查询的方式，使用一个游标来跟踪分页的位置，而不是基于页码，即每次请求从上一次请求的游标开始加载数据，这里我决定使用对话历史的创建时间来当作游标
### 我的方案是使用历史记录中的唯一id和appId和createTime做为联合索引，通过id和createTime作为联合游标进行查询，这样可以避免在高并发的情况下出现时间重复的问题

## 选择使用redis作为缓存对话历史的工具
### 流程：AI对话->从数据库中加载对话到Redis->redis为AI提供对话记忆

## 引入本地缓存 初始化消息列表,避免从数据库中查询的耗时
### 根据方案，对话记忆初始化时，需要从数据库中加载对话历史到记忆中

## 现在后端有一个bug，当我和AI对话的时候，每次AI结束对话之后，直接把AI对话的的内容硬写入源文件中，导致代码丢失。有什么好的办法来区分用户是和AI闲聊，还是AI输出代码要保存修改内容：
### 1. 方案一（AI意图识别）+ 方案四（解析器容错）
### 实施步骤：
1. 优先使用 AI 意图识别
2. 修改 Prompt，让 AI 返回 [CODE] 或 [CHAT] 前缀
3. 前端可以根据前缀调整 UI 显示
4. 兜底使用解析器容错
5. 如果 AI 没有返回前缀标记，通过解析器判断
6. 只有成功解析出有效代码才保存